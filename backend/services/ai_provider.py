"""
OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
"""

import os
import httpx
import logging
from typing import Dict, List, Optional, Any, AsyncIterator
from core.config import settings

logger = logging.getLogger(__name__)


class OpenAIProvider:
    """OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏"""
    
    def __init__(self, api_key: str, proxy_url: str = None):
        self.api_key = api_key
        self.proxy_url = proxy_url
        self.base_url = "https://api.openai.com/v1"
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏ (–º–∞—Å–∫–∏—Ä—É–µ–º –ø–∞—Ä–æ–ª—å)
        if self.proxy_url:
            masked_proxy = self._mask_proxy_password(self.proxy_url)
            logger.info(f"üîó OpenAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å –ø—Ä–æ–∫—Å–∏: {masked_proxy}")
        else:
            logger.info("üîó OpenAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
    
    def _mask_proxy_password(self, proxy_url: str) -> str:
        """–ú–∞—Å–∫–∏—Ä—É–µ—Ç –ø–∞—Ä–æ–ª—å –≤ URL –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ª–æ–≥–æ–≤"""
        if '@' in proxy_url:
            parts = proxy_url.split('@')
            if ':' in parts[0]:
                auth_part = parts[0].split(':')
                auth_part[-1] = '***'  # –ó–∞–º–µ–Ω—è–µ–º –ø–∞—Ä–æ–ª—å
                parts[0] = ':'.join(auth_part)
            return '@'.join(parts)
        return proxy_url
    
    async def get_completion(
        self, 
        messages: List[Dict[str, str]], 
        model: str = "gpt-4o-mini", 
        **kwargs
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI API
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "user", "content": "..."}]
            model: –ú–æ–¥–µ–ª—å OpenAI
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (temperature, max_tokens, etc.)
            
        Returns:
            Dict —Å –æ—Ç–≤–µ—Ç–æ–º –æ—Ç API
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": kwargs.get('temperature', 0.7),
            "max_tokens": kwargs.get('max_tokens', 1000),
            "top_p": kwargs.get('top_p', 1.0),
            "frequency_penalty": kwargs.get('frequency_penalty', 0.0),
            "presence_penalty": kwargs.get('presence_penalty', 0.0),
        }
        
        # –£–¥–∞–ª—è–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
        payload = {k: v for k, v in payload.items() if v is not None}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–æ–∫—Å–∏
        client_kwargs = {"timeout": httpx.Timeout(60.0)}
        if self.proxy_url:
            client_kwargs['proxy'] = self.proxy_url
            logger.debug(f"üîó –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è OpenAI –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ {model}")
        
        async with httpx.AsyncClient(**client_kwargs) as client:
            try:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                data = response.json()
                
                return {
                    "content": data["choices"][0]["message"]["content"],
                    "usage": data.get("usage", {}),
                    "model": data.get("model", model)
                }
            except httpx.HTTPStatusError as e:
                logger.error(f"HTTP error {e.response.status_code} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {e.response.text}")
                raise Exception(f"OpenAI API error {e.response.status_code}: {e.response.text}")
            except httpx.RequestError as e:
                logger.error(f"Request error –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {str(e)}")
                raise Exception(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å OpenAI: {str(e)}")
    
    async def get_streaming_completion(
        self, 
        messages: List[Dict[str, str]], 
        model: str = "gpt-4o-mini", 
        **kwargs
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI API
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            model: –ú–æ–¥–µ–ª—å OpenAI
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Yields:
            Dict —Å —á–∞—Å—Ç—è–º–∏ –æ—Ç–≤–µ—Ç–∞
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": kwargs.get('temperature', 0.7),
            "max_tokens": kwargs.get('max_tokens', 1000),
            "stream": True,
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–æ–∫—Å–∏
        client_kwargs = {"timeout": httpx.Timeout(60.0)}
        if self.proxy_url:
            client_kwargs['proxy'] = self.proxy_url
            logger.debug(f"üîó –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ OpenAI –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ {model}")
        
        async with httpx.AsyncClient(**client_kwargs) as client:
            try:
                async with client.stream(
                    "POST",
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload
                ) as response:
                    response.raise_for_status()
                    
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data_str = line[6:]  # –£–±–∏—Ä–∞–µ–º "data: "
                            if data_str.strip() == "[DONE]":
                                break
                            try:
                                import json
                                data = json.loads(data_str)
                                if data.get("choices") and data["choices"][0].get("delta"):
                                    delta = data["choices"][0]["delta"]
                                    if "content" in delta:
                                        yield {
                                            "content": delta["content"],
                                            "finish_reason": data["choices"][0].get("finish_reason")
                                        }
                            except json.JSONDecodeError:
                                continue
                                
            except httpx.HTTPStatusError as e:
                logger.error(f"HTTP error {e.response.status_code} –ø—Ä–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {e.response.text}")
                raise Exception(f"OpenAI streaming API error {e.response.status_code}: {e.response.text}")
            except httpx.RequestError as e:
                logger.error(f"Request error –ø—Ä–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {str(e)}")
                raise Exception(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å OpenAI –ø—Ä–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–µ: {str(e)}")


def create_openai_provider() -> OpenAIProvider:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    
    Returns:
        OpenAIProvider: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
    """
    api_key = settings.OPENAI_API_KEY
    proxy_url = getattr(settings, 'OPENAI_PROXY_URL', None)
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    return OpenAIProvider(api_key, proxy_url)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
_openai_provider: Optional[OpenAIProvider] = None


def get_openai_provider() -> OpenAIProvider:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    
    Returns:
        OpenAIProvider: –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
    """
    global _openai_provider
    if _openai_provider is None:
        _openai_provider = create_openai_provider()
    return _openai_provider


# –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
class OpenAIClient:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    
    def __init__(self, api_key: str):
        self.provider = OpenAIProvider(api_key, getattr(settings, 'OPENAI_PROXY_URL', None))
    
    class ChatCompletion:
        def __init__(self, provider: OpenAIProvider):
            self.provider = provider
        
        class Completions:
            def __init__(self, provider: OpenAIProvider):
                self.provider = provider
            
            async def create(self, **kwargs):
                """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ completion"""
                messages = kwargs.get('messages', [])
                model = kwargs.get('model', 'gpt-4o-mini')
                
                # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –Ω–∞—à–µ–≥–æ API
                clean_kwargs = {k: v for k, v in kwargs.items() 
                               if k not in ['messages', 'model', 'stream']}
                
                if kwargs.get('stream', False):
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
                    return self.provider.get_streaming_completion(messages, model, **clean_kwargs)
                else:
                    # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                    result = await self.provider.get_completion(messages, model, **clean_kwargs)
                    
                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenAI API
                    class Usage:
                        def __init__(self, usage_data):
                            self.total_tokens = usage_data.get('total_tokens', 0)
                            self.prompt_tokens = usage_data.get('prompt_tokens', 0)
                            self.completion_tokens = usage_data.get('completion_tokens', 0)
                    
                    class Message:
                        def __init__(self, content):
                            self.content = content
                    
                    class Choice:
                        def __init__(self, content):
                            self.message = Message(content)
                    
                    class Response:
                        def __init__(self, result):
                            self.choices = [Choice(result['content'])]
                            self.usage = Usage(result.get('usage', {}))
                            self.model = result.get('model', model)
                    
                    return Response(result)
        
        def __init__(self, provider: OpenAIProvider):
            self.completions = self.Completions(provider)
    
    @property
    def chat(self):
        return self.ChatCompletion(self.provider)